{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset is available at: https://www.kaggle.com/datasets/kreeshrajani/human-stress-prediction.\n",
    "- The motivation behind the dataset is to produce a machine learning model that can prdict if an individual is suffering from a psychological stress or not. \n",
    "- data is captured from multiple subreddits.\n",
    "- The text preprocessing step will mainly analyze the \"text\" column and prep it for the ML analysis. This means we will attept to clean the text as much as possible.\n",
    "- Common text preprocessing step includes: \n",
    "    - Lower casing:\n",
    "        - The idea is to convert all the text into the same casing fromat. For example the inputs of 'hi', 'Hi', and 'HI' will all be treated the same way.\n",
    "        - This is helpful when conducting non-sentiment analysis. However, it could have a slight negative impact for ML models that require the proper casing of the words. E.g., Sentiment Analysis that expects that if a word contians all upper casing characters it represents anger.\n",
    "        - For this project we did not perfrom lower casing because, we are conducting a sentiment analysis.\n",
    "    - Removing any URLs & Emails & HTML tags\n",
    "        - Removal of URL, Emails, and HTML Tags\n",
    "        - The data did not contain any emails. Therefore, np emails were removed \n",
    "    - Punctuations Removal:\n",
    "        - The idea is to remove punctuations the from text data. Therefore, the same text data can be treated the same way even if some have punctuations and others do not. For example \"Yo\" and \"Yo!!!\" will  be treated the same way.\n",
    "        - Also, this step includes Removal of Non-alpha characters\n",
    "        - The most important point in punctuations analysis is the selection of symbols to remove.   \n",
    "    - Stop Words Removal:\n",
    "        - The idea is to remove all the words that commonly occur in the language. E.g., \"a\", \"so\", etc.\n",
    "    - Frequest Words Removal:\n",
    "        - The idea is to remove all the words that commonly occur for specfic type document or text.\n",
    "        - For this project we did not perfrom frequent words removal, because TF-IDF will be taking care of this step.\n",
    "    - Rare Words Removal:\n",
    "        - The idea is to remove all the words that barely occur in text.\n",
    "        - For this project we did not perfrom rare words removal, because TF-IDF will be taking care of this step.\n",
    "    - Stemming:\n",
    "        - The process of reducing inflected words to their word stem by removing the word's suffix and prefix. E.g., converting \"walking\" and \"walks\" to \"walk\". Stemming helps to imporve the computational time\n",
    "        - In this project we did not perform Stemming instead we performed Lemmatization, because Stemming can produce non proper english words.\n",
    "    - Lemmatization:\n",
    "        - Similar to stemming but it does not remove the words' suffix and prefix. It transfom words to their original root word which is called lemma. E.g., converting \"went\" and \"going\" to \"go\". Help to imporve the computational time\n",
    "        - This helps save unnecessary computational overhead in trying to decipher entire words since the meanings of most words are well-expressed by their separate lemmas.\n",
    "    - Emojis Removal/Transformation:\n",
    "        - Removing Emojis from text.\n",
    "        - This task was not conducted in this project.\n",
    "        - ðŸ˜€ is an emoji\n",
    "        - Note: in case of a sentement analysis like the anaysis conducted here. It is prefered that Emojis are translated to words instead of them being removed.  \n",
    "    - Emoticons Removal/Transformation:\n",
    "        - Removing Emoticons from text.\n",
    "        - This task was not conducted in this project, because the text data did not include any Emoticons.\n",
    "        - From Grammarist.com, emoticon is built from keyboard characters that when put together in a certain way represent a facial expression, an emoji is an actual image.\n",
    "        - :-) is an emoticon\n",
    "        - Note: in case of a sentement analysis like the anaysis conducted here. It is prefered that Emoticons are translated to words instead of them being removed.   \n",
    "    - Chatwords Transformation :\n",
    "        - Transforming common chatwords such as BRB to \"Be Right Back\".\n",
    "        - This task was not conducted in this project.\n",
    "    - Spelling Checking:\n",
    "        - Checking the spelling of the data.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the preprocessed data :) \n",
    "- Importing the Libraries\n",
    "- Preping to be worked on DataSet \n",
    "- Data balancing analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              subreddit post_id sentence_range  \\\n",
      "0                 ptsd  8601tu       (15, 20)   \n",
      "1           assistance  8lbrx9         (0, 5)   \n",
      "2                 ptsd  9ch1zh       (15, 20)   \n",
      "3        relationships  7rorpp        [5, 10]   \n",
      "4     survivorsofabuse  9p2gbc         [0, 5]   \n",
      "...                ...     ...            ...   \n",
      "2833     relationships  7oee1t       [35, 40]   \n",
      "2834              ptsd  9p4ung       [20, 25]   \n",
      "2835           anxiety  9nam6l        (5, 10)   \n",
      "2836    almosthomeless  5y53ya        [5, 10]   \n",
      "2837              ptsd  5y25cl         [0, 5]   \n",
      "\n",
      "                                                   text  label  confidence  \\\n",
      "0     He said he had not felt that way before, sugge...      1    0.800000   \n",
      "1     Hey there r/assistance, Not sure if this is th...      0    1.000000   \n",
      "2     My mom then hit me with the newspaper and it s...      1    0.800000   \n",
      "3     until i met my new boyfriend, he is amazing, h...      1    0.600000   \n",
      "4     October is Domestic Violence Awareness Month a...      1    0.800000   \n",
      "...                                                 ...    ...         ...   \n",
      "2833  * Her, a week ago: Precious, how are you? (I i...      0    1.000000   \n",
      "2834  I don't have the ability to cope with it anymo...      1    1.000000   \n",
      "2835  In case this is the first time you're reading ...      0    1.000000   \n",
      "2836  Do you find this normal? They have a good rela...      0    0.571429   \n",
      "2837  I was talking to my mom this morning and she s...      1    0.571429   \n",
      "\n",
      "      social_timestamp  \n",
      "0           1521614353  \n",
      "1           1527009817  \n",
      "2           1535935605  \n",
      "3           1516429555  \n",
      "4           1539809005  \n",
      "...                ...  \n",
      "2833        1515187044  \n",
      "2834        1539827412  \n",
      "2835        1539269312  \n",
      "2836        1488938143  \n",
      "2837        1488909516  \n",
      "\n",
      "[2838 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data\\\\Stress.csv\")\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  He said he had not felt that way before, sugge...      1\n",
      "1  Hey there r/assistance, Not sure if this is th...      0\n",
      "2  My mom then hit me with the newspaper and it s...      1\n",
      "3  until i met my new boyfriend, he is amazing, h...      1\n",
      "4  October is Domestic Violence Awareness Month a...      1\n"
     ]
    }
   ],
   "source": [
    "df = df[['text', 'label']]\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1488\n",
       "0    1350\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Balancing analysis of the label column \n",
    "\n",
    "df[\"label\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data is balanced between 1 (True psychological issues) and 0 (False psychological issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the data to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell to be ignored, because this is a sentiment analysis. Do not run it\n",
    "# df['text_preprocessing_lower'] = df['text'].str.lower()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing URLs & HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PZ4L6Q\\AppData\\Local\\Temp\\ipykernel_27948\\3310036753.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text_preprocessing'] = df['text'].str.replace('http\\S+|www.\\S+', '', case=False) #URLS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  He said he had not felt that way before, sugge...      1   \n",
       "1  Hey there r/assistance, Not sure if this is th...      0   \n",
       "2  My mom then hit me with the newspaper and it s...      1   \n",
       "3  until i met my new boyfriend, he is amazing, h...      1   \n",
       "4  October is Domestic Violence Awareness Month a...      1   \n",
       "\n",
       "                                  text_preprocessing  \n",
       "0  He said he had not felt that way before, sugge...  \n",
       "1  Hey there r/assistance, Not sure if this is th...  \n",
       "2  My mom then hit me with the newspaper and it s...  \n",
       "3  until i met my new boyfriend, he is amazing, h...  \n",
       "4  October is Domestic Violence Awareness Month a...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_preprocessing'] = df['text'].str.replace('http\\S+|www.\\S+', '', case=False) #URLS \n",
    "    #https://stackoverflow.com/questions/51994254/removing-url-from-a-column-in-pandas-dataframe\n",
    "df['text_preprocessing'] = df['text_preprocessing'].str.replace(r'<[^<>]*>', '', regex=True) #HTML Tags\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PZ4L6Q\\AppData\\Local\\Temp\\ipykernel_27948\\600079183.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_preprocessing'][i] = x\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>He said he had not felt that way before sugget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey there rassistance Not sure if this is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>until i met my new boyfriend he is amazing he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  He said he had not felt that way before, sugge...      1   \n",
       "1  Hey there r/assistance, Not sure if this is th...      0   \n",
       "2  My mom then hit me with the newspaper and it s...      1   \n",
       "3  until i met my new boyfriend, he is amazing, h...      1   \n",
       "4  October is Domestic Violence Awareness Month a...      1   \n",
       "\n",
       "                                  text_preprocessing  \n",
       "0  He said he had not felt that way before sugget...  \n",
       "1  Hey there rassistance Not sure if this is the ...  \n",
       "2  My mom then hit me with the newspaper and it s...  \n",
       "3  until i met my new boyfriend he is amazing he ...  \n",
       "4  October is Domestic Violence Awareness Month a...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "for i, x in enumerate(df['text_preprocessing']): \n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    df['text_preprocessing'][i] = x\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PZ4L6Q\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>He said felt way suggeted I go rest TRIGGER AH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey rassistance Not sure right place post goes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>My mom hit newspaper shocked would knows I don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>met new boyfriend amazing kind sweet good stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>October Domestic Violence Awareness Month I do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  He said he had not felt that way before, sugge...      1   \n",
       "1  Hey there r/assistance, Not sure if this is th...      0   \n",
       "2  My mom then hit me with the newspaper and it s...      1   \n",
       "3  until i met my new boyfriend, he is amazing, h...      1   \n",
       "4  October is Domestic Violence Awareness Month a...      1   \n",
       "\n",
       "                                  text_preprocessing  \n",
       "0  He said felt way suggeted I go rest TRIGGER AH...  \n",
       "1  Hey rassistance Not sure right place post goes...  \n",
       "2  My mom hit newspaper shocked would knows I don...  \n",
       "3  met new boyfriend amazing kind sweet good stud...  \n",
       "4  October Domestic Violence Awareness Month I do...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "# len(stop)\n",
    "df['text_preprocessing'] = df['text_preprocessing'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       He said felt way suggeted I go rest TRIGGER AH...\n",
       "1       Hey rassistance Not sure right place post goes...\n",
       "2       My mom hit newspaper shocked would knows I don...\n",
       "3       met new boyfriend amazing kind sweet good stud...\n",
       "4       October Domestic Violence Awareness Month I do...\n",
       "                              ...                        \n",
       "2833    Her week ago Precious I ignored Her Jan 1 Happ...\n",
       "2834    I dont ability cope anymore Im trying lot thin...\n",
       "2835    In case first time youre reading post We looki...\n",
       "2836    Do find normal They good relationship Main pro...\n",
       "2837    I talking mom morning said sister Her trauma w...\n",
       "Name: text_preprocessing, Length: 2838, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_preprocessing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PZ4L6Q\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>He said felt way suggeted I go rest TRIGGER AH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey rassistance Not sure right place post go I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>My mom hit newspaper shocked would know I dont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>met new boyfriend amazing kind sweet good stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>October Domestic Violence Awareness Month I do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  He said he had not felt that way before, sugge...      1   \n",
       "1  Hey there r/assistance, Not sure if this is th...      0   \n",
       "2  My mom then hit me with the newspaper and it s...      1   \n",
       "3  until i met my new boyfriend, he is amazing, h...      1   \n",
       "4  October is Domestic Violence Awareness Month a...      1   \n",
       "\n",
       "                                  text_preprocessing  \n",
       "0  He said felt way suggeted I go rest TRIGGER AH...  \n",
       "1  Hey rassistance Not sure right place post go I...  \n",
       "2  My mom hit newspaper shocked would know I dont...  \n",
       "3  met new boyfriend amazing kind sweet good stud...  \n",
       "4  October Domestic Violence Awareness Month I do...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer() #extract the tokens from stream of words,without whitespaces, new line and tabs\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer() #Perfrom the lemmatization \n",
    "\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "        st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "\n",
    "\n",
    "df['text_preprocessing'] = df.text_preprocessing.apply(lemmatize_text)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the spelling of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PZ4L6Q\\AppData\\Local\\Temp\\ipykernel_27948\\2559197657.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_preprocessing'][i] = x\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>He said felt way suggeted I go rest TRIGGER AH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey rassistance Not sure right place post go I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>My mom hit newspaper shocked would know I dont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>met new boyfriend amazing kind sweet good stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>October Domestic Violence Awareness Month I do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  He said he had not felt that way before, sugge...      1   \n",
       "1  Hey there r/assistance, Not sure if this is th...      0   \n",
       "2  My mom then hit me with the newspaper and it s...      1   \n",
       "3  until i met my new boyfriend, he is amazing, h...      1   \n",
       "4  October is Domestic Violence Awareness Month a...      1   \n",
       "\n",
       "                                  text_preprocessing  \n",
       "0  He said felt way suggeted I go rest TRIGGER AH...  \n",
       "1  Hey rassistance Not sure right place post go I...  \n",
       "2  My mom hit newspaper shocked would know I dont...  \n",
       "3  met new boyfriend amazing kind sweet good stud...  \n",
       "4  October Domestic Violence Awareness Month I do...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker(distance=1) #distance of 1 from the original word\n",
    "\n",
    "def Correct(x):\n",
    "    return spell.correction(x)\n",
    "\n",
    "for i, x in enumerate(df['text_preprocessing']):\n",
    "    x = Correct(x)\n",
    "    df['text_preprocessing'][i] = x\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2838\n",
      "2837\n",
      "                                                text  label  \\\n",
      "0  He said he had not felt that way before, sugge...      1   \n",
      "1  Hey there r/assistance, Not sure if this is th...      0   \n",
      "2  My mom then hit me with the newspaper and it s...      1   \n",
      "3  until i met my new boyfriend, he is amazing, h...      1   \n",
      "4  October is Domestic Violence Awareness Month a...      1   \n",
      "\n",
      "                                  text_preprocessing  \n",
      "0  He said felt way suggeted I go rest TRIGGER AH...  \n",
      "1  Hey rassistance Not sure right place post go I...  \n",
      "2  My mom hit newspaper shocked would know I dont...  \n",
      "3  met new boyfriend amazing kind sweet good stud...  \n",
      "4  October Domestic Violence Awareness Month I do...  \n"
     ]
    }
   ],
   "source": [
    "#dropping empty rows. Then, resetting the index\n",
    "print(len(df))\n",
    "\n",
    "for x in df: \n",
    "    df[x] = df[x].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "df=df.dropna()\n",
    "\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "print(len(df))\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "2833    0\n",
       "2834    1\n",
       "2835    0\n",
       "2836    0\n",
       "2837    1\n",
       "Name: label, Length: 2837, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"label\"].replace([0, 1],['No psychological issues', 'psychological issues'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          psychological issues\n",
       "1       No psychological issues\n",
       "2          psychological issues\n",
       "3          psychological issues\n",
       "4          psychological issues\n",
       "                 ...           \n",
       "2833    No psychological issues\n",
       "2834       psychological issues\n",
       "2835    No psychological issues\n",
       "2836    No psychological issues\n",
       "2837       psychological issues\n",
       "Name: label, Length: 2837, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df [['text_preprocessing', 'label']]\n",
    "df.to_csv(\"Data/ml_nlp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
